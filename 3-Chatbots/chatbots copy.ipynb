{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() ## aloading all the environment variable\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x6ffcd8518890>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x6ffcd859c290>, model_name='deepseek-r1-distill-llama-70b', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"deepseek-r1-distill-llama-70b\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"<think>\\nOkay, so I just met Krish, who's a Chief AI Engineer. I want to respond in a friendly and professional way. First, I should thank him for sharing his role. Then, I can express interest in his work. Maybe ask him what he's working on or what's exciting in AI right now. I should keep it open-ended to encourage a conversation. I don't want to make it too technical unless he brings it up. Just a casual and engaging response.\\n</think>\\n\\nHi Krish, thanks for sharing! It's great to connect with you. How's your work in AI going? Anything exciting projects you're currently involved in or any recent developments in the field that you find particularly interesting?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 146, 'prompt_tokens': 16, 'total_tokens': 162, 'completion_time': 0.530909091, 'prompt_time': 0.003829995, 'queue_time': 0.02103232, 'total_time': 0.534739086}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_56194c30d4', 'finish_reason': 'stop', 'logprobs': None}, id='run-fa172926-4542-448f-bbf7-5aa3560406fe-0', usage_metadata={'input_tokens': 16, 'output_tokens': 146, 'total_tokens': 162})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi , My name is Krish and I am a Chief AI Engineer\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nAlright, the user just asked, \"Hey What\\'s my name and what do I do?\" Let me check the history. In the previous message, they introduced themselves as Krish, a Chief AI Engineer. So, they\\'re testing if I remember that information.\\n\\nI should respond by recalling their name and role. Maybe start with a friendly greeting, then state their name and position. I can also offer further assistance to keep the conversation going.\\n\\nI need to make sure the response is clear and acknowledges their previous introduction. It\\'s important to show that I\\'m attentive and ready to help with whatever they need next.\\n</think>\\n\\nYour name is Krish, and you mentioned you\\'re a Chief AI Engineer. How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 149, 'prompt_tokens': 58, 'total_tokens': 207, 'completion_time': 0.541818182, 'prompt_time': 0.005301902, 'queue_time': 0.022264152, 'total_time': 0.547120084}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_56194c30d4', 'finish_reason': 'stop', 'logprobs': None}, id='run-33427f00-378b-45e2-bdb2-d4869673ada6-0', usage_metadata={'input_tokens': 58, 'output_tokens': 149, 'total_tokens': 207})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi , My name is Krish and I am a Chief AI Engineer\"),\n",
    "        AIMessage(content=\"Hello Krish! It's nice to meet you. \\n\\nAs a Chief AI Engineer, what kind of projects are you working on these days?\\n\\n\"),\n",
    "        HumanMessage(content=\"Hey What's my name and what do I do?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableWithMessageHistory(bound=RunnableBinding(bound=RunnableBinding(bound=RunnableLambda(_enter_history), kwargs={}, config={'run_name': 'load_history'}, config_factories=[])\n",
       "| RunnableBinding(bound=RunnableLambda(_call_runnable_sync), kwargs={}, config={'run_name': 'check_sync_or_async'}, config_factories=[]), kwargs={}, config={'run_name': 'RunnableWithMessageHistory'}, config_factories=[]), kwargs={}, config={}, config_factories=[], get_session_history=<function get_session_history at 0x6ffcd85d1f80>, history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)\n",
    "with_message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bound=RunnableBinding(bound=RunnableBinding(bound=RunnableLambda(_enter_history), kwargs={}, config={'run_name': 'load_history'}, config_factories=[])\n",
      "| RunnableBinding(bound=RunnableLambda(_call_runnable_sync), kwargs={}, config={'run_name': 'check_sync_or_async'}, config_factories=[]), kwargs={}, config={'run_name': 'RunnableWithMessageHistory'}, config_factories=[]) kwargs={} config={} config_factories=[] get_session_history=<function get_session_history at 0x6ffcd85d1f80> history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)]\n"
     ]
    }
   ],
   "source": [
    "print(with_message_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"saurabh\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"<think>\\nAlright, so the user has changed their name from Krish to Saurabh in their latest message. That's interesting. I need to figure out why they did that. Maybe they're testing how the AI responds to different names, or perhaps they made a typo earlier. \\n\\nLooking at the history, the user first introduced themselves as Krish and mentioned that professionals love them for their teaching. The AI responded by highlighting qualities that make Krish appreciated as a teacher. Now, the user is saying their name is Saurabh and repeating the same statement about professionals loving them for teaching.\\n\\nI should consider that the user might be the same person but with a name change, or it could be a different user with a similar context. Either way, the main focus is on the qualities that make a teacher loved by professionals. \\n\\nThe user might be seeking validation or perhaps looking for a response that acknowledges their new name while maintaining the context of their teaching skills. They might be testing the AI's ability to handle name changes while keeping the conversation consistent.\\n\\nI should respond by acknowledging the name change and reinforcing the positive attributes that make Saurabh appreciated as a teacher. It's important to maintain a friendly and supportive tone, similar to the previous response but tailored to the new name.\\n\\nI'll structure the response by listing the qualities again, replacing Krish with Saurabh. This way, the user feels recognized under their new name while the key points about their teaching remain highlighted.\\n\\nI also need to ensure that the response flows naturally and doesn't seem repetitive. Maybe start with a greeting using the new name and then list the qualities, emphasizing why professionals love Saurabh for his teaching.\\n\\nOverall, the goal is to make the user feel acknowledged and appreciated, regardless of the name change, while maintaining the context of their teaching skills.\\n</think>\\n\\nYour name is Saurabh. Professionals love you for your teaching!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 382, 'prompt_tokens': 286, 'total_tokens': 668, 'completion_time': 1.389090909, 'prompt_time': 0.018167943, 'queue_time': 0.023616962999999998, 'total_time': 1.407258852}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_56194c30d4', 'finish_reason': 'stop', 'logprobs': None}, id='run-40dc74cb-39f9-4328-ab59-b7f09dbe1bc7-0', usage_metadata={'input_tokens': 286, 'output_tokens': 382, 'total_tokens': 668})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi , My name is saurabh and professionals love me for my teaching\")],\n",
    "    config=config\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\n\\nYour name is Saurabh.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 309, 'total_tokens': 319, 'completion_time': 0.036363636, 'prompt_time': 0.020982059, 'queue_time': 0.021604608, 'total_time': 0.057345695}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_56194c30d4', 'finish_reason': 'stop', 'logprobs': None}, id='run-e89111cd-a057-47f8-8dd4-1e5d44c453cc-0', usage_metadata={'input_tokens': 309, 'output_tokens': 10, 'total_tokens': 319})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\n\\nYour name is Saurabh.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## change the config-->session id\n",
    "config1={\"configurable\":{\"session_id\":\"saurabh\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Whats my name\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi , My name is Krish and professionals love me for my teaching', additional_kwargs={}, response_metadata={}), AIMessage(content=\"<think>\\nOkay, so I'm Krish, and I need to figure out why professionals love me for my teaching. Hmm, where do I start? Well, first off, I should think about what makes a teacher effective. Maybe it's the way I explain things, or how I connect with my students. Let me break this down.\\n\\nI guess one thing could be my communication skills. If I can explain complex ideas in a simple way, that would make me more effective. But wait, is that enough? Maybe not. I should consider other factors too. Like, do I make my classes interactive? Engagement is important because it keeps students interested and active participants in their learning.\\n\\nAnother thought: maybe it's my patience. Teaching can be tough, especially when students don't get something right away. If I'm patient and take the time to help them understand, that could be a big reason why professionals appreciate me. But I'm not sure if that's the main reason.\\n\\nOh, perhaps it's my ability to adapt to different learning styles. Everyone learns differently, so if I can tailor my teaching methods to suit visual, auditory, or kinesthetic learners, that would make my teaching more effective. That makes sense because not everyone grasps information the same way.\\n\\nWait, maybe it's the resources I provide. If I give my students additional materials or tools beyond the textbook, that could help them learn better. But is that something professionals would specifically love about me? I'm not certain.\\n\\nI should also think about my enthusiasm. If I'm passionate about the subject, that can be contagious. Students might find my classes more enjoyable and motivating if I show genuine interest and excitement. That could be a strong point.\\n\\nAnother angle: maybe I foster a positive learning environment. Creating a safe space where students feel comfortable asking questions and making mistakes can enhance their learning experience. Professionals might appreciate that I not only teach the material but also support the students' emotional and social development.\\n\\nI wonder if it's my use of technology. Incorporating digital tools and modern teaching methods could make my classes more relevant and engaging for today's students. That might be a factor, especially in a rapidly changing world where technology skills are crucial.\\n\\nOh, and maybe my ability to set clear goals and expectations. If I help students set achievable targets and track their progress, it can give them a sense of accomplishment and direction. That kind of structure is probably something professionals value.\\n\\nWait, could it be my continuous improvement? If I'm always looking for ways to better my teaching methods, staying updated with the latest in education, that would make me a more effective educator. Professionals might appreciate my commitment to ongoing learning and development.\\n\\nI'm trying to think if there's anything else. Maybe it's the personalized attention I give to each student. Recognizing that each person has different needs and strengths, and adjusting my teaching accordingly, could be a significant reason. Tailoring lessons to individual learning needs can make a big difference in how much students learn and grow.\\n\\nHmm, I'm also considering whether it's my ability to inspire and motivate. If I can encourage students to take ownership of their learning, set their own goals, and develop a growth mindset, that would have a lasting impact beyond just the classroom. Professionals might love that I not only teach the curriculum but also help students develop essential life skills.\\n\\nWait, but I should be careful not to overcomplicate this. It might be a combination of several factors rather than just one thing. So, maybe the key reasons are my clear communication, adaptability to different learning styles, patience, enthusiasm, and creating a supportive learning environment. All these elements together could make my teaching stand out and be appreciated by professionals.\\n\\nI'm still a bit unsure if I'm covering all the bases. Let me try to summarize. Professionals love me for my teaching because I communicate clearly, adapt my methods to meet individual needs, am patient and supportive, create an engaging and positive environment, and inspire students to take charge of their learning. That sounds comprehensive, but I might have missed something. Maybe my use of real-world examples to make learning relevant? That could be another point. If I connect the material to real-life applications, it makes the content more meaningful and easier to understand.\\n\\nAlso, perhaps my ability to assess student understanding effectively and adjust my teaching on the fly. Being responsive to the needs of the class and making necessary adjustments can ensure that more students grasp the material. That flexibility is important in teaching.\\n\\nI think I've covered a lot of potential reasons. Now, to make sure I'm not missing anything, I'll try to think of it from a student's perspective. What do they value most in a teacher? They might value a teacher who is approachable, knowledgeable, and genuinely cares about their success. If I embody those traits, that would naturally make professionals appreciate my teaching.\\n\\nIn conclusion, I think the main reasons professionals love my teaching are my effective communication, adaptability, patience, enthusiasm, positive learning environment, use of real-world examples, responsiveness to student needs, and genuine care for student success. These factors combined create a supportive and effective learning experience that professionals recognize and appreciate.\\n</think>\\n\\nProfessionals appreciate Krish's teaching for several key reasons:\\n\\n1. **Effective Communication**: Krish explains complex ideas in a clear and simple manner, making the material accessible to all students.\\n\\n2. **Adaptability**: Krish tailors teaching methods to suit different learning styles, ensuring that visual, auditory, and kinesthetic learners all benefit.\\n\\n3. **Patience and Support**: Krish is patient and takes the time to help students understand, creating a safe and comfortable learning environment.\\n\\n4. **Enthusiasm and Passion**: Krish's genuine interest and excitement for the subject matter are contagious, motivating students to engage more deeply.\\n\\n5. **Positive Learning Environment**: Krish fosters a supportive space where students feel comfortable asking questions and making mistakes.\\n\\n6. **Real-World Applications**: Krish connects the material to real-life scenarios, making learning relevant and meaningful.\\n\\n7. **Responsiveness**: Krish assesses student understanding and adjusts teaching strategies as needed, ensuring the class remains effective.\\n\\n8. **Genuine Care**: Krish's approachable nature and genuine concern for student success make him a valued educator.\\n\\nThese qualities combined create a supportive and effective learning experience, earning Krish the appreciation of professionals.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 1287, 'prompt_tokens': 16, 'total_tokens': 1303, 'completion_time': 4.68, 'prompt_time': 0.003828305, 'queue_time': 0.021195003, 'total_time': 4.6838283050000005}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_56194c30d4', 'finish_reason': 'stop', 'logprobs': None}, id='run-30102610-6d73-463f-a020-f89a049a2954-0', usage_metadata={'input_tokens': 16, 'output_tokens': 1287, 'total_tokens': 1303}), HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='<think>\\n\\n</think>\\n\\nYour name is Krish.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 262, 'total_tokens': 272, 'completion_time': 0.036363636, 'prompt_time': 0.017311137, 'queue_time': 0.024277259, 'total_time': 0.053674773}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_af2982c95d', 'finish_reason': 'stop', 'logprobs': None}, id='run-2d3e7508-06be-44a3-be7f-c8d64c939641-0', usage_metadata={'input_tokens': 262, 'output_tokens': 10, 'total_tokens': 272}), HumanMessage(content='Hi , My name is saurabh and professionals love me for my teaching', additional_kwargs={}, response_metadata={}), AIMessage(content=\"<think>\\nAlright, so the user has changed their name from Krish to Saurabh in their latest message. That's interesting. I need to figure out why they did that. Maybe they're testing how the AI responds to different names, or perhaps they made a typo earlier. \\n\\nLooking at the history, the user first introduced themselves as Krish and mentioned that professionals love them for their teaching. The AI responded by highlighting qualities that make Krish appreciated as a teacher. Now, the user is saying their name is Saurabh and repeating the same statement about professionals loving them for teaching.\\n\\nI should consider that the user might be the same person but with a name change, or it could be a different user with a similar context. Either way, the main focus is on the qualities that make a teacher loved by professionals. \\n\\nThe user might be seeking validation or perhaps looking for a response that acknowledges their new name while maintaining the context of their teaching skills. They might be testing the AI's ability to handle name changes while keeping the conversation consistent.\\n\\nI should respond by acknowledging the name change and reinforcing the positive attributes that make Saurabh appreciated as a teacher. It's important to maintain a friendly and supportive tone, similar to the previous response but tailored to the new name.\\n\\nI'll structure the response by listing the qualities again, replacing Krish with Saurabh. This way, the user feels recognized under their new name while the key points about their teaching remain highlighted.\\n\\nI also need to ensure that the response flows naturally and doesn't seem repetitive. Maybe start with a greeting using the new name and then list the qualities, emphasizing why professionals love Saurabh for his teaching.\\n\\nOverall, the goal is to make the user feel acknowledged and appreciated, regardless of the name change, while maintaining the context of their teaching skills.\\n</think>\\n\\nYour name is Saurabh. Professionals love you for your teaching!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 382, 'prompt_tokens': 286, 'total_tokens': 668, 'completion_time': 1.389090909, 'prompt_time': 0.018167943, 'queue_time': 0.023616962999999998, 'total_time': 1.407258852}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_56194c30d4', 'finish_reason': 'stop', 'logprobs': None}, id='run-40dc74cb-39f9-4328-ab59-b7f09dbe1bc7-0', usage_metadata={'input_tokens': 286, 'output_tokens': 382, 'total_tokens': 668}), HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='<think>\\n\\nYour name is Saurabh.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 309, 'total_tokens': 319, 'completion_time': 0.036363636, 'prompt_time': 0.020982059, 'queue_time': 0.021604608, 'total_time': 0.057345695}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_56194c30d4', 'finish_reason': 'stop', 'logprobs': None}, id='run-e89111cd-a057-47f8-8dd4-1e5d44c453cc-0', usage_metadata={'input_tokens': 309, 'output_tokens': 10, 'total_tokens': 319}), HumanMessage(content='Whats my name', additional_kwargs={}, response_metadata={}), AIMessage(content='<think>\\n\\nYour name is Saurabh.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 324, 'total_tokens': 334, 'completion_time': 0.036363636, 'prompt_time': 0.02065474, 'queue_time': 0.022570475999999996, 'total_time': 0.057018376}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_56194c30d4', 'finish_reason': 'stop', 'logprobs': None}, id='run-298ff919-e562-4362-9645-bf285a540de4-0', usage_metadata={'input_tokens': 324, 'output_tokens': 10, 'total_tokens': 334})])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_session_history(\"saurabh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_session_history(\"krish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\n\\nYour name is Saurabh.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey My name is saurbah\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<think>\\n\\nYou've mentioned your name is Saurbah. How can I assist you today?\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Whats my name\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Tempate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant.Amnswer all the question to the best of your ability\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user just said, \"Hi My name is Krish.\" I should respond in a friendly and welcoming manner. Maybe greet him by name and offer assistance. Keep it simple and open-ended so he feels comfortable to ask anything.\\n</think>\\n\\nHi Krish! How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 26, 'total_tokens': 88, 'completion_time': 0.225454545, 'prompt_time': 0.00433205, 'queue_time': 0.020347024, 'total_time': 0.229786595}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_56194c30d4', 'finish_reason': 'stop', 'logprobs': None}, id='run-3af36500-cb0c-4b17-a5a8-729fe5649004-0', usage_metadata={'input_tokens': 26, 'output_tokens': 62, 'total_tokens': 88})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi My name is Krish\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, so I need to figure out how to respond to Krish. He just said \"Hi My name is Krish.\" I should probably greet him back and maybe ask how I can help him today. I want to make sure I\\'m being friendly and approachable. Let me think about the best way to phrase that. Maybe start with a greeting, mention his name, and then offer assistance. Yeah, that sounds good.\\n</think>\\n\\nHi Krish! How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 100, 'prompt_tokens': 26, 'total_tokens': 126, 'completion_time': 0.363636364, 'prompt_time': 0.00418384, 'queue_time': 0.473323934, 'total_time': 0.367820204}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_af2982c95d', 'finish_reason': 'stop', 'logprobs': None}, id='run-52fd2e95-aac9-4cd3-a851-33b32b685fa1-0', usage_metadata={'input_tokens': 26, 'output_tokens': 100, 'total_tokens': 126})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat3\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi My name is Krish\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\n\\nHi Krish! How can I assist you today?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add more complexity\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['language', 'messages'], input_types={'messages': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x6ffcd9768d60>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='You are a helpful assistant. Answer all questions to the best of your ability in {language}.'), additional_kwargs={}), MessagesPlaceholder(variable_name='messages')])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x6ffcd8518890>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x6ffcd859c290>, model_name='deepseek-r1-distill-llama-70b', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nAlright, the user greeted me in English with \"Hi My name is Krish.\" I need to respond in Hindi as per their instruction.\\n\\nI should acknowledge their greeting and thank them for introducing themselves. It\\'s important to be polite and welcoming.\\n\\nI\\'ll start with a common Hindi greeting like \"‡§®‡§Æ‡§∏‡•ç‡§§‡•á\" and then express gratitude. I should also offer my assistance to show I\\'m ready to help.\\n\\nLet me structure it clearly: Greet, thank them, and offer help. Keeping it simple and friendly.\\n</think>\\n\\n‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§ï‡•É‡§∑! ‡§Ü‡§™‡§ï‡§æ ‡§™‡§∞‡§ø‡§ö‡§Ø ‡§¶‡•á‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶‡•§ ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§ï‡§ø‡§∏ ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞ ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å?'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=chain.invoke({\"messages\":[HumanMessage(content=\"Hi My name is Krish\")],\"language\":\"Hindi\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§ï‡•É‡§∑! ‡§Ü‡§™‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§ï‡•É‡§∑ ‡§π‡•à‡•§ ‡§ï‡•ç‡§Ø‡§æ ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§ï‡•Å‡§õ ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å? üòä'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat4\"}}\n",
    "repsonse=with_message_history.invoke(\n",
    "    {'messages': [HumanMessage(content=\"Hi,I am Krish\")],\"language\":\"Hindi\"},\n",
    "    config=config\n",
    ")\n",
    "repsonse.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\n\\n‡§Ü‡§™‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§ï‡•É‡§∑ ‡§π‡•à‡•§ üòä'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"whats my name?\")], \"language\": \"Hindi\"},\n",
    "    config=config,\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing the Conversation History\n",
    "One important concept to understand when building chatbots is how to manage conversation history. If left unmanaged, the list of messages will grow unbounded and potentially overflow the context window of the LLM. Therefore, it is important to add a step that limits the size of the messages you are passing in.\n",
    "'trim_messages' helper to reduce how many messages we're sending to the model. The trimmer allows us to specify how many tokens we want to keep, along with other parameters like if we want to always keep the system message and whether to allow partial messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saurabh-nitro/projects/AgenticAI/Agentic_AI_workspace/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"hi! I'm bob\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='hi!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=60,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nAlright, the user just asked, \"What ice cream do I like.\" Looking back at the conversation history, I remember that earlier they mentioned, \"I like vanilla ice cream.\" So, they\\'ve already shared their preference.\\n\\nI should respond by recalling that information. It shows that I\\'m paying attention and helps keep the conversation personal. I\\'ll say something like, \"You mentioned you like vanilla ice cream!\" to confirm their preference.\\n\\nAlso, since they\\'re asking about their own ice cream preference, it might be a good opportunity to engage further. I can add a question like, \"Is that still your go-to flavor?\" or \"Would you like to try something else?\" to keep the conversation going.\\n\\nI need to make sure the tone stays friendly and open. Using an emoji like üòä can make the response feel warmer and more approachable. So, putting it all together, the reply would be confirming their preference and inviting them to share more if they want.\\n</think>\\n\\nYou mentioned you like vanilla ice cream! üòä Is that still your go-to flavor?'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    "    \n",
    ")\n",
    "response=chain.invoke(\n",
    "    {\n",
    "    \"messages\":messages + [HumanMessage(content=\"What ice cream do i like\")],\n",
    "    \"language\":\"English\"\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, so the user has been chatting with me for a bit. Let me go through the conversation to understand the context better.\\n\\nFirst, the user greeted me as a helpful assistant and said I\\'m good, which is nice. Then they mentioned they like vanilla ice cream, and I responded with \"nice.\" They asked what 2 + 2 is, and I answered 4. They thanked me, and I replied it was no problem. Then they asked if I was having fun, and I said yes.\\n\\nNow, the user is asking, \"what math problem did I ask.\" I need to figure out which math problem they\\'re referring to. Looking back, the only math question was when they asked 2 + 2. So, I should reference that.\\n\\nI should make sure my response is clear and acknowledges their previous question. Maybe I can restate the problem and the answer to confirm. That way, the user knows I\\'m paying attention and can refer back to our conversation.\\n\\nI should also keep the tone friendly and open, inviting them to ask more questions if they need help with anything else. That should cover their query and encourage further interaction if needed.\\n</think>\\n\\nYou asked, \"What is 2 + 2?\" The answer is 4. Let me know if you need help with anything else! üòä'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"what math problem did i ask\")],\n",
    "        \"language\": \"English\",\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
